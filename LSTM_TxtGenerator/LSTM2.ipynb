{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "537aa862-acec-4669-b213-769ad158cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Embedding,Bidirectional,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853c0b42-a288-4fa8-923c-312756260773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(p):\n",
    "    with open(p,'r') as f:\n",
    "        txt = f.read()\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253141f7-6aef-48da-937d-4ba9cbc4c5a3",
   "metadata": {},
   "source": [
    "Disabling them will make the computations faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4705f957-e45a-478a-93a5-516c8b4ac150",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'tagger','ner'])\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff38b36-ca70-46d4-a7bd-20db2554643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2223d378460>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2223d50dec0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2223d5116c0>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1e1c58-c30e-4a9b-bf94-376dacfdfd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    return [tok.text.lower() for tok in nlp(txt) if tok.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc6cf8f-5e0a-4dfb-9aa2-e9d5f7e9074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELmohannd\\anaconda3\\envs\\tensorflow3\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "d = read_file('moby_dick.txt')\n",
    "tokens = tokenize(d)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7107c1a5-bb19-4f37-817a-7dbd55f68574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['call', 'me', 'ishmael', 'some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', 'i', 'thought', 'i', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', 'it', 'is', 'a', 'way', 'i', 'have', 'of', 'driving', 'off', 'the', 'spleen', 'and', 'regulating', 'the', 'circulation', 'whenever', 'i', 'find', 'myself', 'growing', 'grim', 'about', 'the', 'mouth', 'whenever', 'it', 'is', 'a', 'damp', 'drizzly', 'november', 'in', 'my', 'soul', 'whenever', 'i', 'find', 'myself', 'involuntarily', 'pausing', 'before', 'coffin', 'warehouses', 'and', 'bringing', 'up', 'the', 'rear', 'of', 'every', 'funeral', 'i', 'meet', 'and', 'especially', 'whenever', 'my']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2821ef39-5dee-44c8-a9fc-74fc09ce5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25+1\n",
    "text_seq = []\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_seq.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4881461-405b-41ae-bec9-ac118cfbda56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b869801d-b9b3-4b03-9090-203c84e78d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f0d9b06-27de-4451-ad7a-990ef20c200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_seq)\n",
    "sequences = tokenizer.texts_to_sequences(text_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b763fcd8-541f-40ad-acf1-793dba28d543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956,\n",
       " 14,\n",
       " 263,\n",
       " 51,\n",
       " 261,\n",
       " 408,\n",
       " 87,\n",
       " 219,\n",
       " 129,\n",
       " 111,\n",
       " 954,\n",
       " 260,\n",
       " 50,\n",
       " 43,\n",
       " 38,\n",
       " 314,\n",
       " 7,\n",
       " 23,\n",
       " 546,\n",
       " 3,\n",
       " 150,\n",
       " 259,\n",
       " 6,\n",
       " 2713,\n",
       " 14,\n",
       " 24]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b20f551-b232-47c0-8650-8cd83778700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : the\n",
      "1 : a\n",
      "2 : and\n",
      "3 : of\n",
      "4 : i\n",
      "5 : to\n",
      "6 : in\n",
      "7 : it\n",
      "8 : that\n",
      "9 : he\n",
      "10 : his\n",
      "11 : was\n",
      "12 : but\n",
      "13 : me\n",
      "14 : with\n",
      "15 : as\n",
      "16 : at\n",
      "17 : this\n",
      "18 : you\n",
      "19 : is\n",
      "20 : all\n",
      "21 : for\n",
      "22 : my\n",
      "23 : on\n",
      "24 : be\n",
      "25 : 's\n",
      "26 : not\n",
      "27 : from\n",
      "28 : there\n",
      "29 : one\n",
      "30 : up\n",
      "31 : what\n",
      "32 : him\n",
      "33 : so\n",
      "34 : bed\n",
      "35 : now\n",
      "36 : about\n",
      "37 : no\n",
      "38 : into\n",
      "39 : by\n",
      "40 : were\n",
      "41 : out\n",
      "42 : or\n",
      "43 : harpooneer\n",
      "44 : had\n",
      "45 : then\n",
      "46 : have\n",
      "47 : an\n",
      "48 : upon\n",
      "49 : little\n",
      "50 : some\n",
      "51 : old\n",
      "52 : like\n",
      "53 : if\n",
      "54 : they\n",
      "55 : would\n",
      "56 : do\n",
      "57 : over\n",
      "58 : landlord\n",
      "59 : thought\n",
      "60 : room\n",
      "61 : when\n",
      "62 : could\n",
      "63 : n't\n",
      "64 : night\n",
      "65 : here\n",
      "66 : head\n",
      "67 : such\n",
      "68 : which\n",
      "69 : man\n",
      "70 : did\n",
      "71 : sea\n",
      "72 : time\n",
      "73 : other\n",
      "74 : very\n",
      "75 : go\n",
      "76 : these\n",
      "77 : more\n",
      "78 : though\n",
      "79 : first\n",
      "80 : sort\n",
      "81 : said\n",
      "82 : last\n",
      "83 : down\n",
      "84 : most\n",
      "85 : been\n",
      "86 : never\n",
      "87 : your\n",
      "88 : them\n",
      "89 : must\n",
      "90 : tell\n",
      "91 : much\n",
      "92 : good\n",
      "93 : see\n",
      "94 : off\n",
      "95 : myself\n",
      "96 : are\n",
      "97 : yet\n",
      "98 : sleep\n",
      "99 : who\n",
      "100 : seemed\n",
      "101 : light\n",
      "102 : way\n",
      "103 : their\n",
      "104 : just\n",
      "105 : being\n",
      "106 : than\n",
      "107 : place\n",
      "108 : queequeg\n",
      "109 : great\n",
      "110 : long\n",
      "111 : before\n",
      "112 : get\n",
      "113 : round\n",
      "114 : where\n",
      "115 : still\n",
      "116 : any\n",
      "117 : too\n",
      "118 : only\n",
      "119 : door\n",
      "120 : can\n",
      "121 : himself\n",
      "122 : heads\n",
      "123 : come\n",
      "124 : ever\n",
      "125 : two\n",
      "126 : enough\n",
      "127 : made\n",
      "128 : how\n",
      "129 : hand\n",
      "130 : same\n",
      "131 : looking\n",
      "132 : something\n",
      "133 : may\n",
      "134 : '\n",
      "135 : almost\n",
      "136 : say\n",
      "137 : should\n",
      "138 : side\n",
      "139 : why\n",
      "140 : own\n",
      "141 : we\n",
      "142 : new\n",
      "143 : again\n",
      "144 : came\n",
      "145 : arm\n",
      "146 : house\n",
      "147 : away\n",
      "148 : might\n",
      "149 : nothing\n",
      "150 : take\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate(tokenizer.word_index.keys()):\n",
    "    print(i,':',k)\n",
    "    if i == 150:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21816ecb-3e61-42e4-8072-8b6e5f93c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2718"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "947d4a8e-be05-4c6f-8e94-7e5b366d5f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 : call\n",
      "14 : me\n",
      "263 : ishmael\n",
      "51 : some\n",
      "261 : years\n",
      "408 : ago\n",
      "87 : never\n",
      "219 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "954 : precisely\n",
      "260 : having\n",
      "50 : little\n",
      "43 : or\n",
      "38 : no\n",
      "314 : money\n",
      "7 : in\n",
      "23 : my\n",
      "546 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "259 : particular\n",
      "6 : to\n",
      "2713 : interest\n",
      "14 : me\n",
      "24 : on\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(i,':',tokenizer.index_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da7d6823-6a97-45ed-99d7-b76356230e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2718"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sz = len(tokenizer.word_counts)\n",
    "vocab_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b1dbb3-5805-44df-9800-fa447c3453b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ..., 2713,   14,   24],\n",
       "       [  14,  263,   51, ...,   14,   24,  957],\n",
       "       [ 263,   51,  261, ...,   24,  957,    5],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,  262,   53,    2],\n",
       "       [  12,  166, 2712, ...,   53,    2, 2718],\n",
       "       [ 166, 2712,    3, ...,    2, 2718,   26]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af868d32-29cd-4473-abc8-d18ac1872674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3f4da4a-1c91-4449-a1f9-d95d9c59bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
    "    model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(150)))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10d46eb7-efd1-4e3f-b16a-f4e6442603b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = sequences[::3]\n",
    "x = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4166dd8e-94a0-455b-8b48-39f6adc55b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3771, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "312e40d9-bfbc-4a90-be03-310fd2d59aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d796c34b-848c-4fb5-b7d0-d5b03c4eebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y,num_classes=vocab_sz+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18bf2378-fe68-4bed-b8c6-f62cb48c3c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3771, 2719)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd16425c-6f8f-4f90-9101-1c1da45c67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9e118ea-4997-4d8e-8240-619c7316b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 25, 25)            67975     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 25, 300)          211200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 300)              541200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               90300     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2719)              818419    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,729,094\n",
      "Trainable params: 1,729,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_sz+1,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34a8ee65-7faa-4903-b9b0-8d86eed880ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92c35649-42c8-4102-8ff9-6e806f9b2320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 7s 230ms/step - loss: 6.0426 - accuracy: 0.0485\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 8s 257ms/step - loss: 5.9108 - accuracy: 0.0483\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 8s 262ms/step - loss: 5.8593 - accuracy: 0.0456\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 8s 258ms/step - loss: 5.7457 - accuracy: 0.0480\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 9s 299ms/step - loss: 5.6354 - accuracy: 0.0509\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 11s 370ms/step - loss: 5.5271 - accuracy: 0.0557\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 12s 400ms/step - loss: 5.3974 - accuracy: 0.0660\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 12s 399ms/step - loss: 5.2820 - accuracy: 0.0708\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 8s 264ms/step - loss: 5.1858 - accuracy: 0.0692\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 8s 258ms/step - loss: 5.0803 - accuracy: 0.0761\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 8s 253ms/step - loss: 4.9805 - accuracy: 0.0809\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 8s 281ms/step - loss: 4.8865 - accuracy: 0.0841\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 8s 267ms/step - loss: 4.7788 - accuracy: 0.0867\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 10s 336ms/step - loss: 4.6521 - accuracy: 0.0912\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 9s 291ms/step - loss: 4.5300 - accuracy: 0.0947\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 9s 286ms/step - loss: 4.3750 - accuracy: 0.1018\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 11s 367ms/step - loss: 4.1983 - accuracy: 0.1172\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 9s 285ms/step - loss: 4.0270 - accuracy: 0.1260\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 9s 306ms/step - loss: 3.8490 - accuracy: 0.1437\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 8s 284ms/step - loss: 3.6439 - accuracy: 0.1639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2226d66c0a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,batch_size=128,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ac445e7-05b0-46c5-b789-bd61f7c317db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load\n",
    "model.save('epochBIG.h5')\n",
    "dump(tokenizer, open('epochBIG', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fc904c1-b902-4537-a3a6-3e6352261d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])\n",
    "        pad_encoded = pad_sequences(encoded_text, maxlen=seq_len, truncating='pre')\n",
    "        predictions = model.predict(pad_encoded)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        pred_word = tokenizer.index_word[predicted_classes[0]] \n",
    "        input_text += ' ' + pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc5b46d2-946e-41d7-bc79-171d9cc45ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"thought i to myself the man 's a human being just as i am he has just as much reason to fear me as i have\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0,len(text_seq))\n",
    "random_seed_text = text_seq[random_pick]\n",
    "seed_text = ' '.join(random_seed_text)\n",
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d16ac500-9aa6-4035-848e-96ceb31733ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i then i should crawl way or have thinks to get to get and so so so so this idea of me and i be should be be be not be not be be not sure it it was this idea of the same way on it it it it'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f39ad-e007-4569-a8d7-a9e030fcf6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
